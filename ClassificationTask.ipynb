{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load data from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"spambase/spambase.data\",\"r\")\n",
    "lines = [line for line in f]\n",
    "random.shuffle(lines)\n",
    "labels = []\n",
    "features = []\n",
    "for line in lines:\n",
    "    line = line.strip().split(',')\n",
    "    temp = [float(line[x]) for x in range(0,57)]\n",
    "    features.append(temp)\n",
    "    labels.append(int(line[57]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Initialize classifiers\n",
    "There are 8 classification models have been chosen in this task. \n",
    "1. Neural Network classifier\n",
    "2. Support Vector Machine\n",
    "3. Logistic Regression classifier\n",
    "4. Naive Bayes classifier\n",
    "5. K Nearest Neighbor classifier\n",
    "6. Decision Tree\n",
    "7. Random Forest\n",
    "8. Gradient Boosting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(solver='lbfgs', activation='logistic')\n",
    "svm_clf = svm.SVC()\n",
    "lr_clf = LogisticRegression(C=1.0, solver='lbfgs', multi_class='multinomial', max_iter=10000)\n",
    "naive_bayes = MultinomialNB(alpha=0.001, class_prior=None, fit_prior=True)\n",
    "knn = KNeighborsClassifier(n_neighbors=2)\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "random_forest = RandomForestClassifier()\n",
    "gdbt = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize lists to store the result. The scores lists are used to store the corss-validation scores of each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_scores = []\n",
    "svm_scores = []\n",
    "lr_scores = []\n",
    "nb_scores = []\n",
    "knn_scores = []\n",
    "decision_tree_scores = []\n",
    "random_forest_scores = []\n",
    "gdbt_scores = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Perform k-fold cross-validation with k=10\n",
    "For each fold, we first get the train data and test data, then preprocess(standardize) those data for neural network classifier, SVM, logistic regressin classifier and knn. Then calculate the cross-validatin score for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fold = KFold(n_splits=10)\n",
    "for train_indices, test_indices in k_fold.split(features):\n",
    "    x_train = [features[i] for i in train_indices]\n",
    "    x_test = [features[i] for i in test_indices]\n",
    "    y_train = [labels[i] for i in train_indices]\n",
    "    y_test = [labels[i] for i in test_indices]\n",
    "\n",
    "    scaler = preprocessing.StandardScaler().fit(x_train)\n",
    "    x_train_transformed = scaler.transform(x_train)\n",
    "    x_test_transformed = scaler.transform(x_test)\n",
    "    train_data_transformed = np.array(x_train_transformed)\n",
    "    test_data_transformed = np.array(x_test_transformed)\n",
    "\n",
    "    mlp_scores.append(mlp.fit(train_data_transformed, y_train).score(test_data_transformed, y_test))\n",
    "    svm_scores.append(svm_clf.fit(train_data_transformed, y_train).score(test_data_transformed, y_test))\n",
    "    lr_scores.append(lr_clf.fit(train_data_transformed, y_train).score(test_data_transformed, y_test))\n",
    "    knn_scores.append(knn.fit(train_data_transformed, y_train).score(test_data_transformed, y_test))\n",
    "\n",
    "    nb_scores.append(naive_bayes.fit(x_train, y_train).score(x_test, y_test))\n",
    "    decision_tree_scores.append(decision_tree.fit(x_train, y_train).score(x_test, y_test))\n",
    "    gdbt_scores.append(gdbt.fit(x_train, y_train).score(x_test, y_test))\n",
    "    random_forest_scores.append(random_forest.fit(x_train, y_train).score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average cross-validation score of each model is:\n",
      "mlp: 0.9333642365368291\n",
      "svm_clf: 0.9343629161558047\n",
      "lr_clf: 0.9258884278034517\n",
      "naive_bayes: 0.7928642836932943\n",
      "knn: 0.8991483542393661\n",
      "decision_tree: 0.9185818164670375\n",
      "random_forest: 0.9544868433462228\n",
      "gdbt: 0.9459680279166275\n"
     ]
    }
   ],
   "source": [
    "print(\"The average cross-validation score of each model is:\")\n",
    "print(\"mlp: \"+str(np.array(mlp_scores).mean()))\n",
    "print(\"svm_clf: \"+str(np.array(svm_scores).mean()))\n",
    "print(\"lr_clf: \"+str(np.array(lr_scores).mean()))\n",
    "print(\"naive_bayes: \"+str(np.array(nb_scores).mean()))\n",
    "print(\"knn: \"+str(np.array(knn_scores).mean()))\n",
    "print(\"decision_tree: \"+str(np.array(decision_tree_scores).mean()))\n",
    "print(\"random_forest: \"+str(np.array(random_forest_scores).mean()))\n",
    "print(\"gdbt: \"+str(np.array(gdbt_scores).mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above result, we can see that the Random Forest Classifier has highest average cross-validation score, so I choose Random Forest to report the false positive, false negative and overall error rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                False Positive Rate  False Negative Rate  Overall Error Rate\n",
      "Fold1                      0.027119             0.054217            0.036876\n",
      "Fold2                      0.020833             0.052326            0.032609\n",
      "Fold3                      0.025830             0.105820            0.058696\n",
      "Fold4                      0.029520             0.079365            0.050000\n",
      "Fold5                      0.030612             0.036145            0.032609\n",
      "Fold6                      0.028269             0.107345            0.058696\n",
      "Fold7                      0.028269             0.067797            0.043478\n",
      "Fold8                      0.011029             0.069149            0.034783\n",
      "Fold9                      0.018519             0.094737            0.050000\n",
      "Fold10                     0.042146             0.065327            0.052174\n",
      "Avg Error Rate             0.026215             0.073223            0.044992\n"
     ]
    }
   ],
   "source": [
    "report=[]\n",
    "k_fold = KFold(n_splits=10)\n",
    "for train_indices, test_indices in k_fold.split(features):\n",
    "    x_train = [features[i] for i in train_indices]\n",
    "    x_test = [features[i] for i in test_indices]\n",
    "    y_train = [labels[i] for i in train_indices]\n",
    "    y_test = [labels[i] for i in test_indices]\n",
    "    \n",
    "    random_forest.fit(x_train, y_train)\n",
    "    random_forest_predict = random_forest.predict(x_test)\n",
    "    FP = FN = TP = TN = Err = 0\n",
    "    for i in range(len(random_forest_predict)):\n",
    "        if y_test[i] == 0 and random_forest_predict[i]==1:\n",
    "            FP += 1\n",
    "        if y_test[i] == 1 and random_forest_predict[i]==0:\n",
    "            FN += 1\n",
    "        if y_test[i] == random_forest_predict[i] == 1:\n",
    "            TP += 1\n",
    "        if y_test[i] == random_forest_predict[i] == 0:\n",
    "            TN += 1\n",
    "        if y_test[i] != random_forest_predict[i]:\n",
    "            Err += 1\n",
    "    report.append([FP/(FP + TN), FN/(TP + FN), Err/len(random_forest_predict)])\n",
    "    \n",
    "report.append(np.average(report, axis=0))\n",
    "headers1 = [\"Fold1\",\"Fold2\",\"Fold3\",\"Fold4\",\"Fold5\",\"Fold6\",\"Fold7\",\"Fold8\",\"Fold9\",\"Fold10\",\"Avg Error Rate\"]\n",
    "headers2 = [\"False Positive Rate\", \"False Negative Rate\", \"Overall Error Rate\"]\n",
    "print(pandas.DataFrame(report, headers1, headers2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
